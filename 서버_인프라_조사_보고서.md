# 🔍 KOTO 프로젝트 서버 인프라 조사 보고서

**조사일시**: 2026-01-15 20:15 KST  
**대상 서버**: uconcreative.ddns.net (172.30.1.150)  
**조사자**: Antigravity AI (최고관리자 권한)

---

## 📋 Executive Summary

Korean Together (KOTO) 프로젝트를 위한 서버 환경 심층 조사를 완료했습니다.  
현재 서버는 **개발 및 초기 상용 서비스에 매우 적합한 환경**을 보유하고 있으며,  
Docker 기반 마이크로서비스 아키텍처 구축이 즉시 가능합니다.

### 🎯 핵심 결론
1. ✅ **하드웨어**: 충분한 CPU/RAM/Storage, GPU 활용 가능
2. ✅ **기존 인프라**: PostgreSQL, Redis, MinIO 모두 운영 중
3. ✅ **네트워크**: Caddy 리버스 프록시, HTTPS 자동화, `/koto` 경로 이미 등록
4. ✅ **포트**: 5000, 8000 등 사용 가능 포트 충분
5. ⚠️ **Git**: 초기화 필요 (GitHub 저장소는 생성됨)
6. ⚠️ **DB**: `koto` 전용 데이터베이스 생성 필요

### 🚀 즉시 개발 착수 가능 여부
**결론**: **YES** - 모든 필수 인프라가 준비되어 있음

---

## 1. 하드웨어 상세 분석

### 1.1 CPU
```
Model: Intel Core i7-10700F @ 2.90GHz
Cores: 8 physical / 16 threads
Usage: ~40% (현재 다른 프로젝트 실행 중)
```
**평가**: 
- ✅ Node.js API 서버: 여유 충분
- ✅ Python AI 서비스: 동시 처리 가능
- ✅ 동시 세션 50-100개 처리 예상 가능

### 1.2 메모리
```
Total: 32GB
Used: 5GB
Available: 26GB
Swap: 15GB (거의 미사용)
```
**평가**: 
- ✅ KOTO 예상 사용량: 3-5GB (API + AI + DB)
- ✅ 여유 공간으로 모니터링 툴 추가 가능
- ⚠️ 대형 LLM 로컬 로딩 시 제한적 (Gemini API 사용 권장)

### 1.3 스토리지
```
Main Disk (/): 218GB total, 130GB free
Data Disk (/data/db): 916GB total, 870GB free ⭐
Network Storage (/mnt/synology): 8.8TB (shared)
```
**평가**: 
- ✅ `/data/db`를 KOTO 전용 데이터 저장소로 사용 권장
- ✅ PostgreSQL, Redis 볼륨, 음성 파일 저장 공간 충분
- ✅ 백업 공간 넉넉함

### 1.4 GPU
```
Model: NVIDIA GeForce GTX 1060 3GB
CUDA Version: 12.2
Current Usage: 141MB (GUI 전용)
Available VRAM: ~2.9GB
```
**평가**: 
- ✅ Whisper Tiny/Base 모델 로딩 가능 (STT)
- ✅ VITS TTS 모델 추론 가능 (경량화 필요)
- ⚠️ 3GB VRAM으로 대형 LLM 불가 → Gemini API 사용
- 💡 **추천**: Phase S2 이후 로컬 STT/TTS 도입 고려

---

## 2. 네트워크 및 접근 구조

### 2.1 도메인 및 SSL
```
Primary: uconcreative.ddns.net
HTTPS: Caddy 자동 인증서 (Let's Encrypt)
IP: 172.30.1.150 (로컬 네트워크)
```

### 2.2 포트 맵핑 현황

| 포트 | 서비스 | 상태 | 비고 |
|------|--------|------|------|
| 80 | Caddy HTTP | ✅ 운영 중 | HTTPS 리다이렉트 |
| 443 | Caddy HTTPS | ✅ 운영 중 | 메인 게이트웨이 |
| 4000 | Gonggu API | ✅ 운영 중 | Node.js PM2 |
| 4400 | UCONAI API | ✅ 운영 중 | Python (systemd) |
| 5432 | PostgreSQL | ✅ 운영 중 | Docker (localhost) |
| 6379 | Redis | ✅ 운영 중 | Docker (localhost) |
| 8000 | **사용 가능** | 🟢 FREE | KOTO AI 서비스 추천 |
| 8080 | Mongolia Gallery | ✅ 운영 중 | Nginx |
| 8083 | Starverse | ✅ 운영 중 | Docker |
| 9000-9001 | MinIO | ✅ 운영 중 | Object Storage |
| **5000** | **사용 가능** | 🟢 FREE | **KOTO API 추천** ⭐ |

### 2.3 Caddy 리버스 프록시 설정
```caddyfile
# 이미 등록된 경로
handle /koto {\n    redir /koto/ 308\n}\nhandle_path /koto/* {\n    root * /var/www/koto\n    try_files {path} /index.html\n    file_server\n}
```
**현황**:
- ✅ `/var/www/koto` → 정적 파일 서빙 이미 설정됨
- ✅ `/koto-api/*` 추가만 하면 API 연동 완료
- ✅ WebSocket 프록시 추가 필요

---

## 3. 데이터베이스 인프라

### 3.1 PostgreSQL 컨테이너
```
Container: uconai-app_postgres_1
Image: postgres:16
Status: Up 2 weeks (재시작 없음, 안정적)
Port: 127.0.0.1:5432
User: uconai_admin
```

**기존 데이터베이스**:
1. `uconai` - UCONAI 프로젝트
2. `uconai_core` - Core 시스템
3. `gonggu` (소유자: gonggu) - Gonggu 프로젝트
4. `postgres` - 기본 DB

**KOTO를 위한 선택지**:
- **옵션 A**: `uconai_admin` 사용자로 `koto` DB 생성 ⭐ 추천
  - 기존 컨테이너 재사용
  - 관리 단순화
  - 백업 통합

- **옵션 B**: 별도 Docker 컨테이너 생성
  - 포트 5433 사용
  - 완전 격리
  - 마이그레이션 용이

### 3.2 Redis
```
Container: uconai-app_redis_1
Image: redis:7
Status: Up 2 weeks
Port: 127.0.0.1:6379
Persistence: AOF enabled (저장 주기: 60초, 1000 변경)
```
**평가**: 
- ✅ 세션 관리, 캐싱에 즉시 활용 가능
- ✅ KOTO 전용 Key Prefix 사용 (`koto:session:*`)

### 3.3 MinIO (Object Storage)
```
Container: uconai-app_minio_1
Image: minio/minio:latest
Port: 9000 (API), 9001 (Console)
Access: uconai_minio_key / CHANGE_ME_MINIO_SECRET
```
**용도**:
- TTS 오디오 파일 저장 (`/koto-audio/`)
- 레슨 콘텐츠 저장 (`/koto-content/`)
- 학습자 녹음 파일 저장

**액션 필요**:
```bash
mc mb myminio/koto-audio
mc mb myminio/koto-content
mc policy set download myminio/koto-audio
```

---

## 4. 기존 프로젝트 분석 (참고용)

### 4.1 Gonggu 프로젝트
```
위치: /home/ucon/gonggu
구조: Monorepo (apps/api, apps/ai, apps/web)
백엔드: Node.js (PM2 실행 중, 포트 4000)
AI 서버: Python (PM2 실행 중, 828MB 메모리)
데이터베이스: PostgreSQL (gonggu DB)
```
**교훈**:
- ✅ PM2 프로세스 관리 검증됨
- ✅ Docker + PM2 혼합 운영 가능
- ✅ AI 서버 Python FastAPI 구조 참고 가능

### 4.2 UCONAI 프로젝트
```
위치: /home/ucon/UCONAI
Docker Compose: PostgreSQL + Redis + MinIO
Backend: Systemd 서비스 (uconai-iso-backend.service)
Port: 4400
```
**교훈**:
- ✅ Docker Compose 표준 구조 확립
- ✅ Systemd vs PM2 선택 가능
- ✅ `/var/www/` 배포 폴더 규칙

---

## 5. 개발 도구 환경

### 5.1 런타임
```
Node.js: v24.11.1 (최신 버전 ✅)
npm: 11.6.2
Python: 3.12.3
PM2: 설치됨 (프로세스 관리자)
```

### 5.2 Docker 환경
```
Docker: 28.5.2
Docker Compose: 1.29.2
네트워크: bridge, host, 커스텀 네트워크 생성 가능
볼륨: /data/db/에 영구 저장 가능
```

### 5.3 Git 설정
```
User: UCON Creative <uconcreative@gmail.com>
Credential Helper: GitHub CLI (gh)
Default Branch: main
```
**액션 필요**:
- `/home/ucon/koto`에 `git init` 실행
- GitHub remote 연결 (이미 저장소 존재)

---

## 6. 보안 및 접근 제어

### 6.1 방화벽 및 공개 포트
```
Public:
  - 80, 443 (Caddy HTTPS)
  - 9000-9001 (MinIO - 파일 서빙)

Localhost Only:
  - 5432 (PostgreSQL)
  - 6379 (Redis)
  - 4000, 4400, 5000, 8000 (API 서버들)
```
**평가**: ✅ 적절한 보안 설정 (DB는 외부 노출 안 됨)

### 6.2 SSL/TLS
```
Provider: Let's Encrypt (Caddy 자동 갱신)
Wildcard: 미사용 (개별 경로별 인증서)
```

---

## 7. 리소스 예상 사용량 (KOTO 추가 시)

### 현재 사용 중
```
CPU: ~40% (i7-10700F)
RAM: 5GB / 32GB
Disk (/): 77GB / 218GB
Disk (/data/db): 128MB / 916GB
GPU: 141MB / 3GB (GUI만)
```

### KOTO 추가 후 예상
```
CPU: +10-20% → 총 50-60%
RAM: +3-5GB → 총 8-10GB
Disk: +10-50GB (6개월 운영 기준)
GPU: +500MB-1GB (STT/TTS 로컬 모델 사용 시)
```

**판단**: ✅ 전혀 문제없음, 여유 충분

---

## 8. 위험 요소 및 대응 방안

### 🔴 Critical
없음

### 🟡 Medium
1. **단일 서버 의존**
   - 현황: 모든 서비스가 한 서버에 집중
   - 대응: Phase H2에서 DB/Storage 분리 고려

2. **GPU VRAM 제한 (3GB)**
   - 현황: 대형 모델 로딩 불가
   - 대응: 외부 API (Gemini, Google TTS) 활용

3. **백업 자동화 미흡**
   - 현황: 수동 백업 추정
   - 대응: Cron 작업으로 일일 백업 자동화

### 🟢 Low
1. **Redis 비밀번호 미설정**
   - 대응: localhost만 접근 가능하므로 현재는 안전

2. **Docker Compose 버전 (1.29.2)**
   - 대응: 최신 버전 (2.x) 업그레이드 권장

---

## 9. 권장 아키텍처

### 9.1 프로젝트 폴더 구조
```
/home/ucon/koto/
├── api/                    # Node.js API 서버
│   ├── src/
│   ├── tests/
│   └── package.json
├── ai/                     # Python AI 서비스
│   ├── models/
│   ├── services/
│   └── requirements.txt
├── unity/                  # Unity 클라이언트
│   └── Assets/
├── infrastructure/
│   ├── docker/
│   │   └── docker-compose.yml
│   └── scripts/
│       ├── backup.sh
│       └── deploy.sh
├── db/
│   └── migrations/
├── docs/
└── .env.example
```

### 9.2 Docker 서비스 배치
```yaml
services:
  koto-api:       # 포트 5000
  koto-ai:        # 포트 8000 (internal)
  postgres:       # 기존 컨테이너 재사용 또는 새로 생성
  redis:          # 기존 컨테이너 재사용
  minio:          # 기존 컨테이너 재사용
```

### 9.3 프로세스 관리
```
PM2:
  - koto-api (Node.js)
  - koto-ai (Python uvicorn)

Docker:
  - Database (PostgreSQL)
  - Cache (Redis)
  - Storage (MinIO)

Systemd (선택):
  - koto-api.service (PM2 대안)
```

---

## 10. 다음 단계 (승인 후 실행)

### Phase 0: 준비 작업 (30분)
```bash
# 1. Git 초기화
cd /home/ucon/koto
git init
git remote add origin https://github.com/jongjean/koto
echo "node_modules/" > .gitignore
echo ".env" >> .gitignore
echo "*.log" >> .gitignore

# 2. 디렉토리 생성
mkdir -p api/{src,tests,config}
mkdir -p ai/{models,services,utils}
mkdir -p infrastructure/{docker,scripts}
mkdir -p db/migrations
mkdir -p docs

# 3. PostgreSQL DB 생성
docker exec -it uconai-app_postgres_1 psql -U uconai_admin -d postgres \
  -c "CREATE DATABASE koto;"

# 4. MinIO 버킷 생성
mc alias set myminio http://localhost:9000 uconai_minio_key CHANGE_ME_MINIO_SECRET
mc mb myminio/koto-audio
mc mb myminio/koto-content

# 5. 첫 커밋
git add .
git commit -m "Initial project structure"
git push -u origin main
```

### Phase 1: 코어 개발 시작 (Week 1)
1. API 서버 Scaffold (Express + TypeScript)
2. Database 스키마 설계 및 마이그레이션
3. AI 서비스 기본 구조 (FastAPI)
4. Docker Compose 작성 및 테스트

---

## 11. 결론 및 의사결정 필요 사항

### ✅ 즉시 개발 착수 가능 여부
**예 (YES)** - 모든 인프라가 준비되어 있음

### 📋 의사결정 필요 항목

1. **Database 전략**
   - [ ] 옵션 A: 기존 PostgreSQL 컨테이너에 `koto` DB 추가 (추천)
   - [ ] 옵션 B: 별도 PostgreSQL 컨테이너 생성 (포트 5433)

2. **AI 모델 전략**
   - [ ] 옵션 A: 전체 외부 API (Gemini, Google TTS) - 빠른 개발
   - [ ] 옵션 B: Phase S2부터 로컬 모델 도입 (GPU 활용)
   - [ ] 옵션 C: 하이브리드 (평가는 Gemini, TTS는 로컬)

3. **프로세스 관리**
   - [ ] PM2 (기존 프로젝트와 통일)
   - [ ] Systemd (서버 재시작 시 자동 시작)
   - [ ] 혼합 (API는 PM2, AI는 Systemd)

4. **Unity 클라이언트 배포**
   - [ ] WebGL (브라우저에서 실행)
   - [ ] Standalone Windows (다운로드 설치)
   - [ ] 둘 다 제공

5. **초기 언어팩**
   - [ ] KO-EN 먼저 완성 → KO-ID 이식
   - [ ] KO-ID 직접 개발 시작

---

## 📞 Contact & Next Steps

**마스터플랜 문서**: `/home/ucon/koto/MASTER_PLAN.md`

**승인 후 첫 작업**:
```bash
# 아래 명령어 실행 승인 요청
cd /home/ucon/koto
git init
git add README.md MASTER_PLAN.md
git commit -m "Add master plan"
git push -u origin main
```

**예상 개발 기간**:
- Phase S1 (기초 엔진): **3주**
- Phase S2 (AI 연동): **3주**
- Phase S3 (Unity 연동): **4주**
- Phase S4 (ID 언어팩): **4주**
- Phase S5 (상용화): **4주**
- **총 18주 (약 4.5개월)**

---

**보고서 작성**: Antigravity AI  
**최종 검토**: 2026-01-15T20:15:00+09:00  
**버전**: 1.0.0
